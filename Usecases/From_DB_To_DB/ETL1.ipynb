{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81a3b33f-a5cd-4dc7-bc14-5346d369e2d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col,avg,sum,min,max,desc,dense_rank,current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "261a3c8c-295d-4db6-a180-4bd6919fa346",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Spark object\n",
    "spark = SparkSession.builder.appName(\"ETL1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d744a538-619a-4339-8934-d088140d3d6a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Reading data from the given source database table as per provided query\n",
    "def read_data(source_db_url,source_user,source_pwd,query):\n",
    "    df=spark.read.format(\"jdbc\")\\\n",
    "        .option(\"url\", source_db_url)\\\n",
    "        .option(\"user\",source_user)\\\n",
    "        .option(\"password\",source_pwd)\\\n",
    "        .option(\"driver\",\"org.postgresql.Driver\")\\\n",
    "        .option(\"query\", query)\\\n",
    "        .load()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d64e11a0-c6ed-468a-9cca-ab456bd16d8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## DQ Checks\n",
    "## Check Duplicates in df  and nulls in sal\n",
    "def data_quality(dq_df):\n",
    "    filtered_df = dq_df.dropna(subset=\"emp_salary\").dropDuplicates()\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "794ab8bf-25c6-48df-be96-1cd278548b48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Transform the df apply aggregations \n",
    "def transform_source_df(source_df):\n",
    "    windowSpecAgg = Window.partitionBy(\"emp_department\").orderBy(desc(\"emp_salary\"))\n",
    "    transformed_df = source_df.withColumn(\"rank\", dense_rank().over(windowSpecAgg)) \\\n",
    "        .withColumn(\"avg_sal\", avg(col(\"emp_salary\")).over(windowSpecAgg)) \\\n",
    "        .withColumn(\"sum_sal\", sum(col(\"emp_salary\")).over(windowSpecAgg)) \\\n",
    "        .withColumn(\"min_sal\", min(col(\"emp_salary\")).over(windowSpecAgg)) \\\n",
    "        .withColumn(\"max_sal\", max(col(\"emp_salary\")).over(windowSpecAgg)) \\\n",
    "        .where(col(\"rank\") == 1).select(\"emp_department\", \"avg_sal\", \"sum_sal\", \"min_sal\", \"max_sal\", col(\"emp_id\").alias(\"highest_sal_emp_id\"), col(\"emp_name\").alias(\"highest_sal_emp_name\")) \n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bb140ac-8598-4760-a01a-2131f4fe9281",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Write to the destination database table \n",
    "def write_to_postgres(final_df,database_url,postgres_table,properties,mode_of):\n",
    "    try:\n",
    "        final_df.write.jdbc(url=database_url, table=postgres_table, mode=mode_of, properties=properties)\n",
    "        return \"Successfully loaded into postgres\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"Failed to load into Postgres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "691b025b-815f-4106-a861-8b70ba986a53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select * from [REDACTED] where emp_id>10000\nSuccessfully updated checkpoint\nSuccessfully loaded into postgres\n"
     ]
    }
   ],
   "source": [
    "#Get Secrets from Databricks backed key-vault\n",
    "destination_db_url = dbutils.secrets.get('usecaseScope','destination_database_url')\n",
    "destination_user =  dbutils.secrets.get('usecaseScope','destination_user')\n",
    "destination_pwd =   dbutils.secrets.get('usecaseScope','destination_password')\n",
    "destination_table = dbutils.secrets.get('usecaseScope','destination_table')\n",
    "checkpoint_table = dbutils.secrets.get('usecaseScope','checkpoint_table')\n",
    "source_db_url = dbutils.secrets.get('usecaseScope','source_database_url')\n",
    "source_user = dbutils.secrets.get('usecaseScope','source_user')\n",
    "source_pwd = dbutils.secrets.get('usecaseScope','source_password')\n",
    "source_table = dbutils.secrets.get('usecaseScope','source_table')\n",
    "\n",
    "properties = {\n",
    "    \"user\": destination_user ,\n",
    "    \"password\":destination_pwd ,\n",
    "    \"driver\": \"org.postgresql.Driver\"}\n",
    "checkpoint_query = f\"select * from {checkpoint_table}\"\n",
    "\n",
    "try :\n",
    "    max_id_df = read_data(destination_db_url,destination_user,destination_pwd,checkpoint_query)\n",
    "    if not max_id_df.isEmpty():\n",
    "        max_id = max_id_df.select(\"emp_id\").collect()[0][0]\n",
    "        query= f\"select * from {source_table} where emp_id>{max_id}\"\n",
    "    else:\n",
    "        query = f\"select * from {source_table}\"\n",
    "        \n",
    "    #print(query)\n",
    "\n",
    "    source_df = read_data(source_db_url,source_user,source_pwd,query)\n",
    "\n",
    "    if not source_df.isEmpty():\n",
    "        get_max_empid = source_df.select(max(\"emp_id\").alias(\"emp_id\"))\n",
    "        ckp = write_to_postgres(get_max_empid,destination_db_url,checkpoint_table,properties,\"overwrite\")\n",
    "        if ckp:\n",
    "            print(\"Successfully updated checkpoint\")\n",
    "\n",
    "        data_quality_df = data_quality(source_df)\n",
    "        #display(data_quality_df)\n",
    "        transform_df = transform_source_df(data_quality_df)\n",
    "        final_df = transform_df.withColumn(\"timestamp\",current_timestamp())\n",
    "        load = write_to_postgres(final_df,destination_db_url,destination_table,properties,\"append\")\n",
    "        print(load)\n",
    "\n",
    "except Exception as e:\n",
    "    raise Exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8881b65e-53ff-4050-a778-2f431ce0c4b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ETL1",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
